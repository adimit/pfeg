* Search Engine
** Stopwords
   Having stopwords is kinda silly, but I don't see a way around it for now.
* Tasks
** DONE (for now) Find the best (most efficient?) way of searching the indexes
   It seems that there is no way (at all!) to stop tags from adding positional
   information to the index (maybe that'd be worth a bug report.)
   This means that we could keep a base proximity query value of ~1 for every
   query, which increases by *2* for every target word that is not the current
   item's target.

   Might this cause problems?

   Could we just escape this by making t a stop word, then setting stopword step to 0?

   Maybe we should squash all pronouns into one pronoun?

   CHECK WHETHER WE CAN USE THE NEAR OPERATOR NOW INSTEAD OF <<

** Recode matchF and friends
   - matchF needs to get Context (Token Text) instead of Item
   - Bury the Item type (it doesn't seem to be needed anymore
   - check whether PFEG.Pattern produces valid sphinx patterns (maybe also write unit tests!)
   - 
** Ideas
   - Tag sfc forms with prepositions to distinguish canNN and canV and similar
   homophonic but different-part-of-speech words in English.
   - Don't count stuff server-side in searchd, but get the docids, the retrieve
   documents and count everything in pfeg itself, so we can also do advanced
   matches that searchd doesn't support.
   - Only allow certain kinds of words (pos) to be inserted with the proximity
   operator ~n (like adjectives, adverbs, etc, pre/circum-whatever positions.
   It's rule based, but it might improve performance.)
   - Implement asymmetric backoff (this needs trivial changes to the pattern
   data type.)
   - Find most effective patterns (with R?) and then change how a "correct"
   match is found to make it prefer effective patterns.
   - (Optional) Train logistic regression or SVM to give a confidence measure.
   - Implement some sort of frequency measure for words in matches, tf or so.
   - add hashes back into the mix so we don't have duplicate documents?
